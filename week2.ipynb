{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqMCyxCR9eA6iL8ON4wO/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radheshyam1111/CN5006/blob/main/week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V-v8aLxDs9Pg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data (X and Y)\n",
        "X = np.array([1, 2, 3, 4])\n",
        "Y = np.array([2, 3, 5, 7])"
      ],
      "metadata": {
        "id": "-5qvmDzGtUFP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters\n",
        "b0 = 0  # Intercept\n",
        "b1 = 0  # Slope\n",
        "learning_rate = 0.01  # Step size\n",
        "iterations = 1000  # Number of iterations"
      ],
      "metadata": {
        "id": "KV_9shnytalo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples\n",
        "n = len(X)"
      ],
      "metadata": {
        "id": "qGnKhA9VthoC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent function\n",
        "def gradient_descent(X, Y, b0, b1, learning_rate, iterations):\n",
        "    n = len(X)  # Number of samples\n",
        "    for i in range(iterations):\n",
        "        # Predicted Y values (b0 + b1*X) using Linear Regression\n",
        "        Y_pred = b0 + b1 * X\n",
        "\n",
        "        # Compute gradients\n",
        "        db0 = (1/n) * sum(Y_pred - Y)  # Partial derivative wrt b0\n",
        "        db1 = (1/n) * sum((Y_pred - Y) * X)  # Partial derivative wrt b1\n",
        "\n",
        "        # Update parameters\n",
        "        b0 = b0 - learning_rate * db0\n",
        "        b1 = b1 - learning_rate * db1\n",
        "\n",
        "    return b0, b1  # Return the final parameters"
      ],
      "metadata": {
        "id": "bBjtvshWt4yz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Compute gradients\n",
        "        db0 = (1/n) * sum(Y_pred - Y)  # Partial derivative wrt b0\n",
        "        db1 = (1/n) * sum((Y_pred - Y) * X)  # Partial derivative wrt b1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "s9dRJPjkuE8f",
        "outputId": "663f989f-9f6f-4aca-d3fc-eabb376fe621"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-3757061034.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3757061034.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    db0 = (1/n) * sum(Y_pred - Y)  # Partial derivative wrt b0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aa8f6ea",
        "outputId": "872454f4-2dcf-412a-87e3-7d6b34d453e8"
      },
      "source": [
        "# Run the gradient descent function\n",
        "b0_final, b1_final = gradient_descent(X, Y, b0, b1, learning_rate, iterations)\n",
        "\n",
        "# Print the final parameters\n",
        "print(\"Final Intercept (b0):\", b0_final)\n",
        "print(\"Final Slope (b1):\", b1_final)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Intercept (b0): 0.11586119372250991\n",
            "Final Slope (b1): 1.660593065245774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8JrULc4uuaC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}